# 关于我们

## 项目简介

LLM-PPWB (Large Language Model Project Proposal Writing Benchmark) 是一个专注于评估大语言模型在项目申请书写作任务上表现的开源基准测试平台。我们的目标是通过系统性的评估和比较，帮助研究人员和开发者更好地理解和改进大语言模型在专业写作领域的应用。

## 主要功能

- **模型评估**：通过双盲对比实验，评估不同大语言模型在项目申请书写作任务上的表现
- **实时排行榜**：基于ELO评分系统，动态展示各模型的相对排名
- **数据收集**：收集用户对模型输出的评价数据，为后续研究提供支持
- **开源共享**：所有代码和数据集开源，促进社区共同发展

## 技术特点

- 采用Flask框架构建Web应用
- 使用Chart.js实现动态数据可视化
- 基于ELO评分系统进行模型排名
- 支持多模型并行评估

## 联系我们

如果您对我们的项目感兴趣，欢迎通过以下方式联系我们：

- GitHub: [项目地址]
- Email: [qilizhang777@gmail.com]

## 致谢

感谢所有为本项目做出贡献的开发者们！
